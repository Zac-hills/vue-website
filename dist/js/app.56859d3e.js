(function(){"use strict";var e={4469:function(e,t,a){var n=a(5130),i=a(6768),s=a(144),o=a(4232),r=a(5292);const l={class:"flex flex-row"},c={class:"pt-6"};var d=(0,i.pM)({__name:"AnimatedSlide",props:{canToggle:{type:Boolean,default:!1},isTop:{type:Boolean,default:!1},isBottom:{type:Boolean,default:!1},year:{}},setup(e){const t=e,a=(0,s.KR)(!1),n=(0,i.EW)((()=>a.value?"":"hidden")),d=()=>{t.canToggle&&(a.value=!a.value)};return(e,a)=>((0,i.uX)(),(0,i.CE)("div",l,[(0,i.Lk)("div",c,[(0,i.Lk)("div",{class:"flex flex-column flex-auto flex-basis slide",style:(0,o.Tr)(`width:${e.$isMobile()?"80.5vw":"42.5vw"};`)},[(0,i.RG)(e.$slots,"header"),(0,i.bF)((0,s.R1)(r.A),{class:"border-noround-top",label:n.value?"Read More":"Read Less",onClick:d},null,8,["label"]),(0,i.Lk)("div",{class:(0,o.C4)(n.value)},[(0,i.RG)(e.$slots,"content"),(0,i.RG)(e.$slots,"footer")],2)],4)]),(0,i.Lk)("div",{class:(0,o.C4)(["text flex",{"flex-column-reverse":e.isBottom}])},(0,o.v_)(t.year),3),(0,i.Lk)("div",{class:(0,o.C4)(["flex flex-grow",{"border-right":e.isTop,bottom:e.isBottom,dash:!e.isBottom}])},null,2)]))}}),u=a(1241);const h=(0,u.A)(d,[["__scopeId","data-v-b7a1a19c"]]);var p=h;const g=e=>((0,i.Qi)("data-v-26844c2a"),e=e(),(0,i.jt)(),e),m=g((()=>(0,i.Lk)("video",{controls:""},[(0,i.Lk)("source",{src:"signature.mp4",type:"video/mp4"}),(0,i.eW)(" Your browser does not support the video tag. ")],-1))),f=g((()=>(0,i.Lk)("div",{class:"text-left p-3"},[(0,i.Lk)("h2",null,"Signature - Senior Software Engineer"),(0,i.Lk)("p",null," I was the sole developer on the Signature project, responsible for its design, implementation, and deployment. Signature is a web application tailored for Forensic Linguistic Analysts, enabling them to apply their expertise at scale—a significant improvement in a field traditionally dominated by labor-intensive processes. "),(0,i.Lk)("p",null," Forensic Linguistics typically requires a high level of expertise, with analysts spending many hours to meticulously analyze a single document. Signature addresses this challenge by providing tools that allow analysts to markup and define patterns in text, which can then be applied across an entire corpus. This capability means that once an analyst identifies specific features in one document, those features can be used to automatically scan the entire dataset for similar characteristics. "),(0,i.Lk)("p",null," This approach allows analysts to quickly identify other relevant documents, significantly speeding up the process and improving efficiency in cases requiring linguistic analysis. "),(0,i.Lk)("p",null," Signature’s architecture uses a horizontal scaling approach for the ingest pipeline, designed to handle vast amounts of data and integrate additional processing steps seamlessly. This scalability ensures that the system can grow and adapt to the increasing demands of forensic analysis, making it a powerful tool for analysts working on complex cases. ")],-1)));var v=(0,i.pM)({__name:"SignatureSlide",setup(e){return(e,t)=>((0,i.uX)(),(0,i.Wv)(p,{isTop:"",canToggle:"",year:"2024"},{header:(0,i.k6)((()=>[m])),content:(0,i.k6)((()=>[f])),_:1}))}});const w=(0,u.A)(v,[["__scopeId","data-v-26844c2a"]]);var k=w;const b=e=>((0,i.Qi)("data-v-4f9c99c2"),e=e(),(0,i.jt)(),e),y=b((()=>(0,i.Lk)("img",{src:"/leadlag-header.png",class:"max-width-40"},null,-1))),L=b((()=>(0,i.Lk)("div",{class:"text-left p-3"},[(0,i.Lk)("h2",null,"Consilium Maps"),(0,i.Lk)("p",{class:"text"},[(0,i.eW)(' Consilium Maps is a data exploratory tool based on the lead-lag metric, which measures the offset between research outputs of different countries. For example, a search for "spinach" shows how each country’s research output compares to Canada’s. This tool uses data from '),(0,i.Lk)("a",{href:"https://www.dimensions.ai/"},"Dimensions.AI"),(0,i.eW)(", which includes over 108 million papers with metadata on authors, affiliations, funding, citations, and patents. ")]),(0,i.Lk)("p",{class:"text"},[(0,i.eW)(" To manage the vast dataset, we use a progressive loader that allows interaction with partially loaded data. The scrubber represents Canada’s data and can be resized to select between 3 and 10 years. This helps users gauge areas of interest in Canada’s research output over time. "),(0,i.Lk)("img",{src:"/leadlag-scrubber.png",alt:"Scrubber interface displaying a portion of Canada's research data. Users can interact with and resize this tool to view different time spans of data, which helps in analyzing trends and areas of interest.",class:"p-2"})]),(0,i.Lk)("p",{class:"text"},[(0,i.eW)(" Event graphs highlight regions with the most significant lead, lag, and participation from various countries. These graphs provide a clear visualization of global research dynamics and help identify key trends and areas with notable research activity. "),(0,i.Lk)("img",{src:"/leadlag-events.png",alt:"Event graphs showcasing regions with the highest lead and lag in research output. The graphs also highlight regions with the most participating countries, providing an overview of global research trends.",class:"p-2"})]),(0,i.Lk)("p",{class:"text"},[(0,i.eW)(" After selecting a timespan, users can view individual institutions' outputs relative to Canada. Nodes on the map indicate whether an institution is leading or lagging in research output compared to Canada. Trend lines on these nodes show significant changes in output, with an upward trend indicating a 5% or more increase. "),(0,i.Lk)("img",{src:"/leadlag-nodes.png",alt:"Map showing individual institutions with nodes indicating their research output relative to Canada. Each node’s color represents lead or lag status, and the trend line displays changes in output over the selected timespan.",class:"w-full p-2"})]),(0,i.Lk)("p",{class:"text"}," Consilium Maps aims to provide stakeholders with valuable insights into institutional performance on a global scale, helping to assess how well different institutions and countries are performing in various research areas. ")],-1)));var x=(0,i.pM)({__name:"LeadLagSlide",setup(e){return(e,t)=>((0,i.uX)(),(0,i.CE)("div",null,[(0,i.bF)(p,{canToggle:!0,year:"2019"},{header:(0,i.k6)((()=>[y])),content:(0,i.k6)((()=>[L])),_:1})]))}});const T=(0,u.A)(x,[["__scopeId","data-v-4f9c99c2"]]);var I=T;const _=e=>((0,i.Qi)("data-v-72eefad9"),e=e(),(0,i.jt)(),e),S=_((()=>(0,i.Lk)("iframe",{src:"https://www.youtube.com/embed/4phJmMGCcCc?si=wjv8hHp28j9KFQCa&controls=0",title:"YouTube video player",frameborder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share",referrerpolicy:"strict-origin-when-cross-origin",class:"aspect",allowfullscreen:""},null,-1))),j=_((()=>(0,i.Lk)("div",{class:"text-left p-3"},[(0,i.Lk)("h2",null," Spatial Evaluation of Convolutional Neural Networks using UAVs "),(0,i.Lk)("p",{className:"article-text"}," Convolutional Neural Networks suffer from a lack of explaination when it comes to their use. The current standard for depicting a convolutional neural network's capability has a dependency on the dataset that was used to train and test it. For example, this convolutional neural network has a 92% accuracy using some dataset. In order for you to comprehend the convolutional neural networks capabilities you have to be an expert on the dataset used. Even if you are an expert, it still does not define how well the convolutional neural network will preform in a 3 dimensional environment. For example, questions such as at what distance does the network start to lose accuracy, what are the weak view points such as the front or back of the object, and how well does the network preform when both the viewpoint and distance are dynamic. "),(0,i.Lk)("p",{className:"article-text"},[(0,i.eW)(" This projects presents another approach to depicting the behaviour of a convolutional neural network. I am not stating that the previous approach is worse, it is the appropriate approach for debugging and training a network. The change in accuracy for a datasets depicts how your network topology changes are impacting the accuracy of the network. However, once the network is fully trained and the parameters are tuned there must be a better way to help developers understand the limitations of the network. "),(0,i.Lk)("img",{src:"/spatial_visual.png",class:"p-3 w-full"}),(0,i.eW)(" This project uses unmanned aerial vehicles to circle the object logging the images and spatial data relative to the object. The result is a detailed visual analysis of the spatial limitations of the neural network. By providing the spatial limitations engineers who are looking to use the network will have a better understanding of how the network will perform making it easier for the engineers to make decisions. Take Tesla for example, they have two sets of convolutional neural network models, one network for objects that are closer and another for further away objects, this is a perfect example of where understanding the spatial limitations is a neccessity. ")]),(0,i.Lk)("p",null,[(0,i.eW)(" The above image depicts a single distance from the object of 25 meters, for a more detailed analysis it is crucial to have more than a single pass around the object. Below is an image that depicts a composite of multiple fly bys with a distance of 10, 15, 20, and 25m from the object. The angle of incidence is represented, where the 0 degree is true north. The object's front should face true north to better calculate the angle of incidence relative to the object's rotation, for objects that are symmetrical this is not mandatory. "),(0,i.Lk)("img",{src:"/visualmodel.PNG",class:"p-3 w-full img-aspect"})]),(0,i.Lk)("p",null," In conclusion this work is an approach to help engineers be informed about the spatial limitations of convolutional neural networks. The project uses data visualization to help aid in the understanding of the limitations, and uses an unmanned aerial vehicle to gather the spatial data. ")],-1)));var A=(0,i.pM)({__name:"SpatialEvalSlide",setup(e){return(e,t)=>((0,i.uX)(),(0,i.CE)("div",null,[(0,i.bF)(p,{canToggle:"",year:"2018",isBottom:""},{header:(0,i.k6)((()=>[S])),content:(0,i.k6)((()=>[j])),_:1})]))}});const F=(0,u.A)(A,[["__scopeId","data-v-72eefad9"]]);var C=F;const M=e=>((0,i.Qi)("data-v-49804915"),e=e(),(0,i.jt)(),e),E=M((()=>(0,i.Lk)("iframe",{src:"https://vialab.github.io/tied-in-knots/#/",class:"aspect"},null,-1))),z=M((()=>(0,i.Lk)("div",{class:"text-left p-3"},[(0,i.Lk)("h2",null,"Tied In Knots"),(0,i.Lk)("p",null," Tied in Knots is an interactive visualization with the objective of providing insight and spread awareness about sexual assaults in academia. One of the challenges of this project is to provide analytics without minimizing the individual accounts. The typical methods for data visualization use some form of summary in order to simplify the dataset allowing the user to gleam insights more quickly with less \"clutter\". When the data you are dealing with is the individual's first hand account of their traumatic experience the traditional methods of summary is not only incorrect and inappropriate -- the traditional approaches are damaging and minimizes the individual's traumatic experience. "),(0,i.Lk)("p",null,[(0,i.eW)(' The challenge of keeping every data point as part of the visualization brought a necessity for high performance rendering. There was also the goal for mobile and tablet support which further increased the need for a high performance rendering solution. The original solution used D3 and SVG in order to create the text that followed the spline. Upon clicking the text the text would unravel allowing the user to see the first hand accounts of that particular person. The "knots" themselves are tied based on their '),(0,i.Lk)("a",{href:"https://en.wikipedia.org/wiki/Coding_(social_sciences)"},"manual coding"),(0,i.eW)(". Due to the use of text and the necessity for grouping and performing animations on them the initial prototype struggled to run on modern laptops. ")]),(0,i.Lk)("p",null," My task was to increase performance while keeping the same design. D3 uses SVG which is a mature technology however it lacks the performance that WebGL can offer. The solution that gave the best performance was switching to a WebGL based rendering system using the library Pixi.js. Even with WebGL's performance increases it was not enough to support straight text rendering. I created a tool that exported the SVG text to a png at the required resolution, the new images were added to a texture atlas so the application only had to do one texture binding which dramatically increased performance. To address the unraveling of the text a hybrid method was created. When the user clicks on one of the text images, a svg is created with the text and the knot is unravelled. The overall solution gave a performance increase of over 1400%, while meeting all of the design and platform criteria. ")],-1)));var W=(0,i.pM)({__name:"TiedInKnotsSlide",setup(e){return(e,t)=>((0,i.uX)(),(0,i.Wv)(p,{year:"2019",canToggle:""},{header:(0,i.k6)((()=>[E])),content:(0,i.k6)((()=>[z])),_:1}))}});const D=(0,u.A)(W,[["__scopeId","data-v-49804915"]]);var R=D;const q=e=>((0,i.Qi)("data-v-0f864dd6"),e=e(),(0,i.jt)(),e),B=q((()=>(0,i.Lk)("img",{src:"/distil-map.gif",alt:"Distil Map"},null,-1))),O=q((()=>(0,i.Lk)("div",{class:"text-left p-3"},[(0,i.Lk)("h2",null,"Distil - Software Engineer"),(0,i.Lk)("ul",null,[(0,i.Lk)("li",null,[(0,i.Lk)("strong",null,"Developing the Interactive Analytic Workflow:"),(0,i.Lk)("ul",null,[(0,i.Lk)("li",null,"Designed and implemented the user interface for the question-first analytic process."),(0,i.Lk)("li",null,"Created interactive tools and components to guide users through problem definition and solution exploration."),(0,i.Lk)("li",null,"Integrated backend services to support dynamic data interaction and workflow management.")])]),(0,i.Lk)("li",null,[(0,i.Lk)("strong",null,"Implementing Data Discovery and Enrichment:"),(0,i.Lk)("ul",null,[(0,i.Lk)("li",null,"Built and optimized data retrieval systems to facilitate the discovery of relevant datasets."),(0,i.Lk)("li",null,"Developed data enrichment algorithms and integrated external data sources to enhance dataset quality and relevance."),(0,i.Lk)("li",null,"Ensured seamless data integration and preprocessing pipelines.")])]),(0,i.Lk)("li",null,[(0,i.Lk)("strong",null,"Creating Model Recommendation Systems:"),(0,i.Lk)("ul",null,[(0,i.Lk)("li",null,"Designed and developed machine learning algorithms for model recommendation based on user-defined problems and data characteristics."),(0,i.Lk)("li",null,"Implemented model selection and evaluation logic to suggest appropriate analytic models."),(0,i.Lk)("li",null,"Integrated recommendation systems into the user interface for a smooth user experience.")])]),(0,i.Lk)("li",null,[(0,i.Lk)("strong",null,"Developing Automated Visualization Features:"),(0,i.Lk)("ul",null,[(0,i.Lk)("li",null,"Implemented algorithms for automated visualization of data and model results."),(0,i.Lk)("li",null,"Designed and created visualization components to help users interpret model outputs and data insights."),(0,i.Lk)("li",null,"Integrated visualization tools into the user interface for real-time analysis and adjustments.")])]),(0,i.Lk)("li",null,[(0,i.Lk)("strong",null,"Building Ambient Visualization and Information Retrieval Systems:"),(0,i.Lk)("ul",null,[(0,i.Lk)("li",null,"Developed features for document organization and classification using inferred tags from classifiers."),(0,i.Lk)("li",null,"Implemented tagging and retrieval systems to enhance document management and organization."),(0,i.Lk)("li",null,"Integrated these features with existing document management systems for improved user experience.")])]),(0,i.Lk)("li",null,[(0,i.Lk)("strong",null,"Implementing Semi-Supervised Machine Learning Techniques:"),(0,i.Lk)("ul",null,[(0,i.Lk)("li",null,"Designed and developed algorithms combining supervised and unsupervised learning techniques for iterative model refinement."),(0,i.Lk)("li",null,"Implemented systems to handle both labeled and unlabeled data for improving model accuracy."),(0,i.Lk)("li",null,"Integrated semi-supervised learning components into the overall modeling workflow.")])])])],-1)));var G=(0,i.pM)({__name:"DistilSlide",setup(e){return(e,t)=>((0,i.uX)(),(0,i.Wv)(p,{canToggle:"",year:"2020"},{header:(0,i.k6)((()=>[B])),content:(0,i.k6)((()=>[O])),_:1}))}});const X=(0,u.A)(G,[["__scopeId","data-v-0f864dd6"]]);var N=X;const P=e=>((0,i.Qi)("data-v-10b13d37"),e=e(),(0,i.jt)(),e),Q=P((()=>(0,i.Lk)("img",{src:"/terrorarium.png"},null,-1))),V=P((()=>(0,i.Lk)("div",{class:"p-3 text-left"},[(0,i.Lk)("h2",null,"Terrorarium - Senior Software Engineer"),(0,i.Lk)("p",null," As a Senior Software Engineer on the Terrorarium project, I played a pivotal role in extending and enhancing an already beloved game. My primary responsibility was to develop a substantial expansion that not only added new levels, mechanics, and challenges but also preserved the essence of the original gameplay that fans had come to love. This involved working closely with designers and artists to ensure that the new content seamlessly integrated into the existing game world, maintaining a consistent and engaging player experience. "),(0,i.Lk)("p",null," In addition to content development, I took the lead in integrating support for the TiltFive platform, a cutting-edge mixed reality technology. This required adapting and optimizing Terrorarium for a new dimension of gameplay, allowing players to experience the game in an entirely new way. I developed custom Unity engine plugins that facilitated this integration, ensuring that the game could leverage TiltFive’s unique capabilities without sacrificing performance or stability. "),(0,i.Lk)("p",null," The work on this project involved a deep dive into Unity’s engine architecture, where I implemented new tools and processes to streamline the development pipeline. These tools not only sped up the iteration process but also ensured that all team members could work efficiently within the expanded scope of the game. My contributions helped to ensure that the final product was polished, innovative, and delivered on time, providing players with a rich and immersive experience. ")],-1)));var $=(0,i.pM)({__name:"TerrorarriumSlide",setup(e){return(e,t)=>((0,i.uX)(),(0,i.Wv)(p,{canToggle:"",year:"2023"},{header:(0,i.k6)((()=>[Q])),content:(0,i.k6)((()=>[V])),_:1}))}});const K=(0,u.A)($,[["__scopeId","data-v-10b13d37"]]);var U=K,H=a(2160);const Z=e=>((0,i.Qi)("data-v-befd5c7a"),e=e(),(0,i.jt)(),e),Y={class:"h-screen w-screen flex flex-column overflow-hidden no-scrollbar"},J={key:0,class:"flex flex-row justify-content-center no-scrollbar overflow-hidden"},ee={class:"slide flex align-items-center pr-5vw overflow-hidden"},te=(0,i.Fv)('<div class="flex justify-content-between" data-v-befd5c7a><h1 class="text-left p-3" data-v-befd5c7a>Zachary Hills, BIT, MSc</h1><div class="p-3 flex align-items-center" data-v-befd5c7a><a class="pi pi-github p-3" href="https://github.com/Zac-hills" data-v-befd5c7a></a><a class="pi pi-linkedin p-3" href="https://www.linkedin.com/in/zachary-hills-031333185/?originalSubdomain=ca" data-v-befd5c7a></a></div></div>',1),ae=Z((()=>(0,i.Lk)("h3",{class:"text-left"},"Experience:",-1))),ne=Z((()=>(0,i.Lk)("p",{class:"text-left w-8 pl-3"}," I am a Senior Full Stack Engineer and Data Scientist with extensive experience working on DARPA and IARPA contracts. My expertise spans a diverse range of applications, from leveraging AI for Forensic Linguistics to enhancing spectral imagery with advanced AI techniques. Additionally, I have a strong background in designing and implementing horizontal scaling architecture to ensure robust and efficient system performance. ",-1))),ie={class:"flex flex-column overflow-y-auto overflow-x-hidden no-scrollbar mb-6",ref:"container"},se={key:1,class:"overflow-y-auto"},oe={class:"mb-3"},re=(0,i.Fv)('<div class="flex justify-content-between" data-v-befd5c7a><h1 class="text-left p-3" data-v-befd5c7a>Zachary Hills, BIT, MSc</h1><div class="p-3 flex align-items-center" data-v-befd5c7a><a class="pi pi-github p-3" href="https://github.com/Zac-hills" data-v-befd5c7a></a><a class="pi pi-linkedin p-3" href="https://www.linkedin.com/in/zachary-hills-031333185/?originalSubdomain=ca" data-v-befd5c7a></a></div></div>',1),le=Z((()=>(0,i.Lk)("h3",{class:"text-left"},"Experience:",-1))),ce=Z((()=>(0,i.Lk)("p",{class:"text-left p-3"}," I am a Senior Full Stack Engineer and Data Scientist with extensive experience working on DARPA and IARPA contracts. My expertise spans a diverse range of applications, from leveraging AI for Forensic Linguistics to enhancing spectral imagery with advanced AI techniques. Additionally, I have a strong background in designing and implementing horizontal scaling architecture to ensure robust and efficient system performance. ",-1)));var de=(0,i.pM)({__name:"App",setup(e){return(e,t)=>((0,i.uX)(),(0,i.CE)("div",Y,[e.$isMobile()?((0,i.uX)(),(0,i.CE)("div",se,[(0,i.Lk)("div",oe,[re,(0,i.bF)((0,s.R1)(H.A)),le,ce]),(0,i.bF)(k),(0,i.bF)(U,{class:"border-right"}),(0,i.bF)(N,{class:"border-right"}),(0,i.bF)(R,{class:"border-right"}),(0,i.bF)(I,{class:"border-right"}),(0,i.bF)(C,{class:"border-right"})])):((0,i.uX)(),(0,i.CE)("div",J,[(0,i.Lk)("div",ee,[(0,i.Lk)("div",null,[te,(0,i.bF)((0,s.R1)(H.A)),ae,ne])]),(0,i.Lk)("div",ie,[(0,i.bF)(k),(0,i.bF)(U,{class:"border-right"}),(0,i.bF)(N,{class:"border-right"}),(0,i.bF)(R,{class:"border-right"}),(0,i.bF)(I,{class:"border-right"}),(0,i.bF)(C,{class:"border-right"})],512)]))]))}});const ue=(0,u.A)(de,[["__scopeId","data-v-befd5c7a"]]);var he=ue,pe=a(8253),ge=a(9890),me=a(2169),fe=a.n(me);(0,n.Ef)(he).use(pe.Ay,{theme:{preset:ge.A}}).use(fe()).mount("#app")}},t={};function a(n){var i=t[n];if(void 0!==i)return i.exports;var s=t[n]={exports:{}};return e[n].call(s.exports,s,s.exports,a),s.exports}a.m=e,function(){var e=[];a.O=function(t,n,i,s){if(!n){var o=1/0;for(d=0;d<e.length;d++){n=e[d][0],i=e[d][1],s=e[d][2];for(var r=!0,l=0;l<n.length;l++)(!1&s||o>=s)&&Object.keys(a.O).every((function(e){return a.O[e](n[l])}))?n.splice(l--,1):(r=!1,s<o&&(o=s));if(r){e.splice(d--,1);var c=i();void 0!==c&&(t=c)}}return t}s=s||0;for(var d=e.length;d>0&&e[d-1][2]>s;d--)e[d]=e[d-1];e[d]=[n,i,s]}}(),function(){a.n=function(e){var t=e&&e.__esModule?function(){return e["default"]}:function(){return e};return a.d(t,{a:t}),t}}(),function(){a.d=function(e,t){for(var n in t)a.o(t,n)&&!a.o(e,n)&&Object.defineProperty(e,n,{enumerable:!0,get:t[n]})}}(),function(){a.g=function(){if("object"===typeof globalThis)return globalThis;try{return this||new Function("return this")()}catch(e){if("object"===typeof window)return window}}()}(),function(){a.o=function(e,t){return Object.prototype.hasOwnProperty.call(e,t)}}(),function(){var e={524:0};a.O.j=function(t){return 0===e[t]};var t=function(t,n){var i,s,o=n[0],r=n[1],l=n[2],c=0;if(o.some((function(t){return 0!==e[t]}))){for(i in r)a.o(r,i)&&(a.m[i]=r[i]);if(l)var d=l(a)}for(t&&t(n);c<o.length;c++)s=o[c],a.o(e,s)&&e[s]&&e[s][0](),e[s]=0;return a.O(d)},n=self["webpackChunksite"]=self["webpackChunksite"]||[];n.forEach(t.bind(null,0)),n.push=t.bind(null,n.push.bind(n))}();var n=a.O(void 0,[504],(function(){return a(4469)}));n=a.O(n)})();
//# sourceMappingURL=app.56859d3e.js.map